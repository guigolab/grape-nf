= Grape Quickstart
:nf-web: http://nextflow.io
:nf-docs: http://www.nextflow.io/docs/latest/index.html
:nf-docs-sharing: http://www.nextflow.io/docs/latest/sharing.html
:nf-docs-executors: http://www.nextflow.io/docs/latest/executor.html
:nf-docs-envvars: http://www.nextflow.io/docs/latest/config.html#environment-variables
:nf-docs-profiles: http://www.nextflow.io/docs/latest/config.html#config-profiles
:grape-repo: https://github.com/guigolab/grape-nf.git


Grape provides an extensive pipeline for RNA-Seq analyses. It allows the creation of an automated and integrated workflow to manage
and analyse RNA-Seq data.

It uses {nf-web}[Nextflow^] as the execution backend and can be installed and run in a very simple way. Using Nextflow sharing
features, the pipeline is automatically downloaded from the {grape-repo}[Grape Github repository^] and run on the local environment. Please check
{nf-docs}[Nextflow documentation^] for more information.

== Installing Nextflow

Nextflow can be installed with the following commands:

[source,bash]
----
curl -fsSL get.nextflow.io | bash
mv nextflow <folder in your path>
----

Check the installed version:

[source,bash]
----
nextflow info
----

[source,bash]
----
  Version: 0.17.3 build 3495
  Modified: 18-02-2016 11:00 UTC (12:00 CEST)
  System: Mac OS X 10.10.5
  Runtime: Groovy 2.4.5 on Java HotSpot(TM) 64-Bit Server VM 1.8.0_40-b27
  Encoding: UTF-8 (UTF-8)
----

NOTE: Nextflow installation is only required once. You might need to <<_upgrade_nextflow_version, upgrade>> it, though.

== Upgrade Nextflow version

The pipeline requires Nextflow version [red]#0.14.0# or higher. Make sure you have the right version by running `nextflow info`. In case
you have an older version you can upgrade as follows:

[source,bash]
----
nextflow -self-update
----

== Setting up the pipeline

The pipeline will be automatically downloaded the first time if it is not found on the local system. To run the pipeline the
following command is used:

[source,bash]
----
nextflow run guigolab/grape-nf ...
----

The command above will not update the pipeline if it is already present in the system. In order to always run the latest version
it is possible to download the pipeline in advance and then run it:

[source,bash]
----
nextflow pull guigolab/grape-nf
nextflow run grape-nf ...
----

[NOTE]
Downloading the pipeline in advance also allows to run the it without specifying the repository `owner` (have a look at the
{nf-docs-sharing}[Nextflow documentation about this feature^]).


== Running the pipeline

Using Nextflow, the pipeline can be run on the local machine, on a computational grid or the cloud without any change to the actual code.
By default a local executor is used, but it can be changed by using {nf-docs-executors}[Nextflow executors^].

For example, to run the pipeline in a computational cluster using Sun Grid Engine you will need to set up a Nextflow configuration file
containing something like:

[source,groovy]
----
process {
    executor = 'sge'
    queue    = 'my-queue'
    penv     = 'mpi'
}
----

=== Creating a working directory

Move to the folder where you want to create the base directory for the pipeline and run the following command:

[source,bash]
----
mkdir -p <folder name> && cd <folder name>
----

=== Reference files

Only genome FASTA file and annotation file are required. Reference files can be specified using absolute paths or relative
paths to a local folder where links to the files can be created:

[source,bash]
----
mkdir refs
ln -s <path to the genome file> refs
ln -s <path to the annotation file> refs
----

=== Getting the help

You can get the pipeline help by using the following command:

[source,bash]
----
nextflow run grape-nf --help
----

[source%nowrap,bash]
----
N E X T F L O W  ~  version 0.17.3
Launching 'guigolab/grape-nf' - revision: 777fd2c6e9 [master]

G R A P E ~ RNA-seq Pipeline
----------------------------
Run the GRAPE RNA-seq pipeline on a set of data.

Usage:
    grape-pipeline.nf --index INDEX_FILE --genome GENOME_FILE --annotation ANNOTATION_FILE [OPTION]...

Options:
    --help                              Show this message and exit.
    --index INDEX_FILE                  Index file.
    --genome GENOME_FILE                Reference genome file(s).
    --annotation ANNOTAION_FILE         Reference gene annotation file(s).
    --steps STEP[,STEP]...              The steps to be executed within the pipeline run. Possible values: "mapping", "bigwig", "contig", "quantification". Default: all
    --max-mismatches THRESHOLD          Set maps with more than THRESHOLD error events to unmapped. Default "4".
    --max-multimaps THRESHOLD           Set multi-maps with more than THRESHOLD mappings to unmapped. Default "10".
    --bam-sort METHOD                   Specify the method used for sorting the genome BAM file.
    --add-xs                            Add the XS field required by Cufflinks/Stringtie to the genome BAM file.

SAM read group options:
    --rg-platform PLATFORM              Platform/technology used to produce the reads for the BAM @RG tag.
    --rg-library LIBRARY                Sequencing library name for the BAM @RG tag.
    --rg-center-name CENTER_NAME        Name of sequencing center that produced the reads for the BAM @RG tag.
    --rg-desc DESCRIPTION               Description for the BAM @RG tag.
----

=== Input format

The pipeline needs a tab separated file as an input. This file should contain information about the FASTQ files to be processed. The
columns needed in order are:

[cols="1,l,1",options="autowidth"]
|===
| [red]#{counter:index-qs}# | sample | the sample identifier, used to merge bam files in case multiple runs for the same sample are present
| [red]#{counter:index-qs}# | id     | the run identifier (e.g. labExpId)
| [red]#{counter:index-qs}# | path   | the path to the fastq file
| [red]#{counter:index-qs}# | type   | the type (e.g. fastq)
| [red]#{counter:index-qs}# | view   | an attribute that specifies the content of the file (e.g. FastqRd1)
|===

Here is an example:

[source]
----
sample1  test1   data/test1_1.fastq.gz   fastq   FastqRd1
sample1  test1   data/test1_2.fastq.gz   fastq   FastqRd2
----

Sample and id can be the same in case you don't have/know sample identifiers:

[source]
----
test     test    data/test.fastq.gz      fastq   FastqRd
----

Also bam files can be specified in the index, with or without fastqs:

[source]
----
sample1  test1   data/test1_1.fastq.gz   fastq   FastqRd1
sample1  test1   data/test1_2.fastq.gz   fastq   FastqRd2
sample2  test2   data/test2.bam          bam     Alignment
----

In this case the bam file will skip the mapping process and will be sent to the subsequent processes.

WARNING: Bam and fastq files should not refer to the same sample unless you want to merge them


=== Run the pipeline

Here is a simple example of how you can run the pipeline:

[source,bash]
----
nextflow -bg run grape-nf --index input-files.tsv --genome refs/hg38.AXYM.fa --annotation refs/gencode.v21.annotation.AXYM.gtf --rg-platform ILLUMINA --rg-center-name CRG -resume 2>&1 > pipeline.log
----

By default the pipeline execution will stop as far as one of the processes fails. To change this behaviour you can use the [errorStrategy directive](http://www.nextflow.io/docs/latest/process.html#errorstrategy) of Nextflow processes. You can also specify it on command line. For example, to ignore errors and keep processing you can use ``-process.errorStrategy=ignore``.

It is also possible to run a subset of pipeline steps using the option ``--steps``. For example, the following command will only run the ``mapping`` and ``quantification`` steps:

[source,bash]
----
nextflow -bg run grape-nf --steps mapping,quantification --index input-files.tsv --genome refs/hg38.AXYM.fa --annotation refs/gencode.v21.annotation.AXYM.gtf --rg-platform ILLUMINA --rg-center-name CRG -resume 2>&1 > pipeline.log
----

### Stop the pipeline

To stop a running pipeline just run the following command from within the pipeline base directory:

[source,bash]
----
kill $(cat .nextflow.pid)
----

[NOTE]
If you run multiple pipelines within the same folder (e.g. for different genders), please use the
{nf-docs-envvars}[NXF_PID_FILE^] environment variable.

=== Job monitoring

Nextflow runs all processes in an isolated directory under the pipeline working folder (by default `./work`). Each process is
configured and run by means of several files contained in the process folder. Among those files some can be worth noting:

[cols="10l,90"]
|===
| file name    | description

| .command.env | the process environment
| .command.out | the process standard output
| .command.err | the process standard error
| .command.log | when run on a compute cluster, the process log output from the job execution
| .command.run | the script submitted to the cluster (also contains the header with cluster directives)
| .command.sh  | the actual executed command
| .exitcode    | the exit status of the command
|===

A process can then be easily monitored by inspecting the process folder. Each process is uniquely represented by a hash string
internally computed by Nextflow using the command string and its inputs. To inspect a process folder just look for Nextflow
submission messages in the pipeline log file, which look like the following:

[source,bash]
----
...
[b5/0e02e9] Submitted process > index (1)
...
----

The string between square brackets represents the prefix of the relative path to the process folder starting from the `work` directory.
In order to inspect the process working folder for the `index (1)` process above just do:

[source,bash]
----
find work/b5 -name '0e02e9*' -exec ls -a {} \+
----

[source,bash]
----
.  ..  .command.begin  .command.env  .command.out  .command.run  .command.sh  .command.val  .exitcode  genome_index.gem  genome_index.log  hg38_AXM.fa
----

== Pipeline profiles

The Grape pipeline can be run using different configuration profiles. The profiles essentially allow the user to run the analyses using
different tools and configurations. The following profiles are available at present:

[cols="10l,90"]
|===
| profile  | description

| gemflux  | uses `GEMtools` for mapping pipeline and `Flux Capacitor` for isoform expression quantification
| starrsem | uses `STAR` for mapping and bigwig and `RSEM` for isoform expression quantification
| starflux | uses `STAR` for mapping and `Flux Capacitor` for isoform expression quantification
|===

The default profile uses `STAR` and `RSEM` and set the `--bam-sort` option to `samtools`.

To specify a profile you can use the {nf-docs-profiles}[`-profiles` Nextflow option^].
For example, the command:

[source,bash]
----
nextflow -bg run grape-nf -profile starrsem --index input-files.tsv --genome refs/hg38.AXYM.fa --annotation refs/gencode.v21.annotation.AXYM.gtf --rg-platform ILLUMINA --rg-center-name CRG -resume 2>&1 > pipeline.log
----

will run Grape using the `starrsem` profile.
